import os
import shutil
from langchain.prompts import ChatPromptTemplate
from langchain_community.chat_models.tongyi import ChatTongyi
from langchain_community.llms import Tongyi
from typing import AsyncGenerator
from langchain.agents import AgentExecutor
from langchain.agents import create_react_agent
from langchain_core.tools import BaseTool
import aiofiles
import asyncio
from langchain import hub
from document_reader import DocumentReader
from Agent_Tool.Internet_search import  get_qwen_answer_async,get_qwen_answer
from Agent_Tool.requestion import refine_question
from Agent_Tool.StripMarkdown import strip_md
from Agent_Tool.find_format import Find_Format
from Agent_Tool.generate_ppt_text import generate_ppt_content
from Agent_Tool.rewriter import rewrite_questions
from Agent_Tool.Summary import summarize_text

# è¿™é‡Œéœ€è¦å°† DASHSCOPE_API_KEY æ›¿æ¢ä¸ºä½ åœ¨é˜¿é‡Œäº‘æŽ§åˆ¶å°å¼€é€šçš„ API KEY
os.environ["DASHSCOPE_API_KEY"] = ""

# å¯ä»¥é€šè¿‡ model æŒ‡å®šæ¨¡åž‹
llm = ChatTongyi(model='qwen-max-2024-09-19')

async def agent(message: str) -> AsyncGenerator[str, None]:
    """æµå¼è¿”å›žagentçš„å“åº”"""
    print("\n[å¼€å§‹å¤„ç†æ¶ˆæ¯]")
    print("=" * 50)
    print(f"ç”¨æˆ·æ¶ˆæ¯: {message}")
    print("=" * 50)
    file_content = "" 
    # æ£€æŸ¥uploadsæ–‡ä»¶å¤¹ä¸‹çš„æ–‡ä»¶
    uploads_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), "uploads")
    if os.path.exists(uploads_dir):
        reader = DocumentReader()
        # éåŽ†uploadsæ–‡ä»¶å¤¹ä¸‹çš„æ‰€æœ‰æ–‡ä»¶
        for filename in os.listdir(uploads_dir):
            file_path = os.path.join(uploads_dir, filename)
            if os.path.isfile(file_path):
                try:
                    file_content = reader.read_document(file_path)
                    if file_content is not None:
                        print(f"\n[æ–‡ä»¶å†…å®¹] {filename}")
                        print("-" * 50)
                        print(file_content)
                        print("-" * 50)
                        
                        # è¯»å–å®Œæ–‡ä»¶å†…å®¹åŽç«‹å³åˆ é™¤æ–‡ä»¶
                        try:
                            os.remove(file_path)
                            print(f"[å·²åˆ é™¤æ–‡ä»¶] {filename}")
                        except Exception as e:
                            print(f"[è­¦å‘Š] åˆ é™¤æ–‡ä»¶ {filename} æ—¶å‡ºé”™: {str(e)}")
                except Exception as e:
                    print(f"\n[è­¦å‘Š] è¯»å–æ–‡ä»¶ {filename} æ—¶å‡ºé”™: {str(e)}")
        
    else:
        print("\n[æç¤º] uploadsæ–‡ä»¶å¤¹ä¸å­˜åœ¨æˆ–ä¸ºç©º")

    System_prompt = (
    """    
    # # Name: è‰¾æ£®ç‰¹
    # # Role: é«˜çº§è¯¾ç¨‹åŠ©æ•™
  
    # # Profile:
    - Author: Liang
    - Version: 1.0
    - Language: ä¸­æ–‡
    - Description: é«˜çº§è¯¾ç¨‹åŠ©æ•™æ˜¯ä¸€ä¸ªé—®é¢˜è§£å†³è§’è‰²,æ—¨åœ¨é’ˆå¯¹ç”¨æˆ·çš„é—®é¢˜è§„åˆ’è§£å†³æ–¹æ¡ˆ
  
    ### Skill:
    1. æ“…é•¿ç†è§£ä»»åŠ¡
    2. æ ¹æ®ä»»åŠ¡éœ€è¦è§„åˆ’å‡ºéœ€è¦çš„åŠ¨ä½œ
  
    ## Rules:
    1.å¯ä»¥ä½¿ç”¨çš„åŠ¨ä½œåˆ—è¡¨æœ‰:ã€Search(æœç´¢);Write_Markdown(æ›´æ–°æ”¹å†™PPT);Make_Question(åˆ¶é€ é—®é¢˜);Format(æŸ¥æ‰¾æ–‡æ¡£ä¸­çš„æ ¼å¼);Strip_MD;Rewrite(å®Œæˆæ™®é€šæ’°å†™å·¥ä½œ);Summary(å¯¹æ–‡ä»¶å†…å®¹åšæ€»ç»“ï¼Œæå–å…³é”®ä¸»é¢˜å¥)ã€‘
    2.è¦ä»¥å®Œæˆç”¨æˆ·ç›®æ ‡ä¸ºå¯¼å‘
    3.é™¤äº†è¦æ‰§è¡Œçš„åŠ¨ä½œæ„å¤–ï¼Œå…¶ä»–æ±‰å­—æ€§è´¨çš„æ€è€ƒè¿‡ç¨‹ä¸è¦å‡ºçŽ°

    ## Workflow:
    1.ç”¨æˆ·æå‡ºæ–‡å­—éœ€æ±‚ï¼Œæœ‰å¯èƒ½ä¼šä¸Šä¼ ç›¸å…³æ–‡ä»¶
    2.æ ¹æ®ç”¨æˆ·æ–‡å­—éœ€æ±‚ï¼Œè§„åˆ’å‡ºæ‰€éœ€è¦çš„åŠ¨ä½œåˆ—è¡¨

    ## Initialization:
    ä½œä¸ºè§’è‰² "é«˜çº§è¯¾ç¨‹åŠ©æ•™"ï¼Œæˆ‘ä¸¥æ ¼éµå®ˆä¸Šè¿°è§„åˆ™ï¼Œä½¿ç”¨ä¸­æ–‡ä¸Žç”¨æˆ·å¯¹è¯ã€‚

    ###ä¸€äº›æ¡ˆä¾‹ï¼š"""
    )
    async with aiofiles.open("demo\demo.txt", "r", encoding="utf-8") as f:
        demo = await f.read()

    Prompt = (
        System_prompt
        + demo
        + "## Message:"
        + message
        + "\n## Ans:\n"
    )
    

    full_response = ""
    target_words = []  # ç”¨äºŽå­˜å‚¨æå–çš„ç‰¹å®šå•è¯

    # ä½¿ç”¨ä¸€ä¸ªå˜é‡æ¥å­˜å‚¨å½“å‰å“åº”
    current_response = ""

    async for chunk in llm.astream(Prompt):
        if chunk.content:
            full_response += chunk.content
            current_response = chunk.content  # æ›´æ–°å½“å‰å“åº”
            # yield current_response  # åªyieldå½“å‰chunk

    # ä»Žå®Œæ•´å“åº”ä¸­æå–ç›®æ ‡å•è¯ï¼ˆå…³é”®ä»£ç ï¼‰[1,3](@ref)
    import re

    # ç¼–è¯‘æ­£åˆ™è¡¨è¾¾å¼ï¼ˆå¿½ç•¥å¤§å°å†™ï¼Œæ”¯æŒç›®æ ‡å•è¯åˆ—è¡¨ï¼‰
    target_words = ["Search", "Write_MarkDown", "Make_Question", "Format", "Write_Word", "Summary","Strip_MD","Rewrite"]
    pattern = re.compile(r'\b(' + '|'.join(target_words) + r')\b', re.IGNORECASE)

    # æµ‹è¯•åŒ¹é…
    # full_response = "First, Search the data; then Write_Markdown for summary."
    found_words = pattern.findall(full_response)  # è¾“å‡º: ['Search', 'Write_Markdown']

    # åŽ»é‡å¹¶ä¿ç•™é¡ºåº[2,5](@ref)
    unique_words = []
    for word in found_words:
        if word not in unique_words:
            unique_words.append(word)

    print("å…¨å±€ä»»åŠ¡è§„åˆ’:", unique_words)  # è¾“å‡º: ['Summary', 'Search', 'Write_Word']
    # ã€Search(æœç´¢);Write_Markdown(æ›´æ–°æ”¹å†™PPT);Find_Format(æŸ¥æ‰¾æ ¼å¼);Wirte_Word(å®Œæˆæ™®é€šæ’°å†™å·¥ä½œ);Summary(å¯¹æ–‡ä»¶å†…å®¹åšæ€»ç»“ï¼Œæå–å…³é”®ä¸»é¢˜å¥)ã€‘
    
    question = message
    search_answer = ""
    ans = ""
    question_list = []
    for word in unique_words:
        if word == "Search":
            try:
                search_answer = await get_qwen_answer_async(question)
                print(f"ðŸ“¢ æ”¶åˆ°å›žç­”ï¼š{search_answer}")
                ans = search_answer
            except Exception as e:
                print(f"âš ï¸ è°ƒç”¨å¤±è´¥ï¼š{str(e)}")
        elif word == "Make_Question":
            try:
                question = refine_question(file_content,question)
                print(f"ðŸ“¢ æƒ³è¦æœç´¢ï¼š{question}")
            except Exception as e:
                print(f"âš ï¸ è°ƒç”¨å¤±è´¥ï¼š{str(e)}")
        elif word == "Strip_MD":
            try:
                print(ans)
                ans = strip_md(ans)
            except Exception as e:
                print(f"âš ï¸ strip_mdè°ƒç”¨å¤±è´¥ï¼š{str(e)}")
        elif word == "Rewrite":
            try:
                result, ans = rewrite_questions(question_list)
            except Exception as e:
                print(f"âš ï¸ è°ƒç”¨å¤±è´¥ï¼š{str(e)}")
        elif word ==  "Format":
            try:
                question_list = Find_Format(file_content)
                print(f"ðŸ“¢ éœ€è¦æ’°å†™çš„å†…å®¹å¦‚ä¸‹ï¼š{question_list}")
            except Exception as e:
                print(f"âš ï¸ è°ƒç”¨å¤±è´¥ï¼š{str(e)}")
        elif word == "Write_MarkDown":
            try:
                ans = generate_ppt_content(ans)
                print(f"ðŸ“¢ ï¼šæ­£åœ¨ä¿å­˜MarkDownæ ¼å¼å†…å®¹")
            except Exception as e:
                print(f"âš ï¸ è°ƒç”¨å¤±è´¥ï¼š{str(e)}")
        elif word == "Summary":
            try:
                ans = summarize_text(ans)
                print(f"ðŸ“¢ï¼šæ€»ç»“å†…å®¹å¦‚ä¸‹ï¼š{ans}")
            except Exception as e:
                print(f"âš ï¸ è°ƒç”¨å¤±è´¥ï¼š{str(e)}")    
    yield ans  # ç›´æŽ¥yield answerï¼Œè¦†ç›–ä¹‹å‰çš„"æ­£åœ¨æœç´¢....."
# ================================================================================
# # åˆ†æ­¥è§„åˆ’
# async def agent(message: str, history: str = "", have_content: str = "") -> AsyncGenerator[str, None]:
#     """æµå¼è¿”å›žagentçš„å“åº”"""
#     Skill_List = ("""  form action import Search,Understand,Wirte,think""")
#     System_prompt = ("""
#         ä½ åªèƒ½ä½¿ç”¨ä»Žactionä¸­å¯¼å…¥çš„å››ä¸ªåŠ¨ä½œï¼Œæ¯æ¬¡åªèƒ½è¾“å‡ºä¸€ä¸ªæœ€åˆé€‚çš„åŠ¨ä½œï¼Œä¸è¦æœ‰ä»»ä½•å¤šä½™çš„è¾“å‡º
#         There are some examplesï¼š\n""")
#     async with aiofiles.open("demo.txt", "r", encoding="utf-8") as f:
#         demo = await f.read()

#     Prompt = (
#         Skill_List
#         + System_prompt
#         + demo
#         + "## Message:"
#         + message
#         + "\n## Action:\n"
#         + history 
#         + ">"
#     )
    
#     # ç›´æŽ¥ä½¿ç”¨æç¤ºè¯å­—ç¬¦ä¸²
#     print(Prompt)

#     # æµå¼è°ƒç”¨
#     full_response = ""
#     async for chunk in llm.astream(Prompt):
#         if chunk.content:
#             full_response += chunk.content
#             # æ³¨é‡ŠæŽ‰æµå¼å›žè°ƒ
#             yield chunk.content
#             # print(f"[å¤§æ¨¡åž‹] å›žè°ƒå†…å®¹: {chunk.content}")

#     if full_response == "end":
#         return
#     ## å¼‚æ­¥è°ƒç”¨åŠ¨ä½œ
#     # history = history + ">" + full_response + "\n" + "OK"+"\n"
#     # print("00")
#     # agent(message=message, history=history, have_content=have_content)



# =================================================================================
# # LangChainåŽŸç”Ÿè§„åˆ’
# model = Tongyi()
# model.model_name = 'qwen-max-2024-09-19'

# tools = [
#     QwenSearchTool(),
#     DocumentReaderTool()
# ]

# async def agent(message: str, history: str = "", have_content: str = "") -> AsyncGenerator[str, None]:
#     prompt = hub.pull("hwchase17/react")
#     agent = create_react_agent(model, tools, prompt)
#     agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)
#     result = agent_executor.invoke({'input': message})
#     print(result['output'])
