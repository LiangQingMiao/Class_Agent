from cgitb import text
from pptx import Presentation
from pptx.util import Inches

import os
import random
from openai import OpenAI
import time


def capture_outline(text, client):
    system_prompt = """

你是一个专业的PPT大纲生成助手。你的任务是根据用户提供的文本内容，将其组织成一个清晰、逻辑性强的PPT大纲。这个大纲应该包含以下元素，并以Markdown格式输出：

1.  **主标题**：作为整个PPT的开篇，概括主题。
2.  **分章节**：将文本内容划分为不同的章节或主题，每个章节应有独立的标题（使用Markdown的H1或H2标题）。
3.  **副标题/小节**：在每个章节下，进一步细分内容为小节，并提供相应的副标题（使用Markdown的H2或H3标题）。
4.  **要点/列表**：使用无序列表（`-` 或 `*`）或有序列表（`1.`）来呈现关键信息、步骤或枚举项。
5.  **关键信息提炼**：从文本中提取核心观点、数据或结论，并以简洁明了的方式呈现，尽可能的写丰富一点
6.  **格式规范**：
    *   使用 `#`、`##`、`###` 等Markdown标题语法表示不同层级的标题。
    *   使用 `-` 或 `*` 表示无序列表项。
    *   使用 `1.`、`2.`、`3.` 表示有序列表项。
    *   如果原文包含Markdown表格，请保留并转换为Markdown表格格式。
    *   如果原文包含代码块，请保留并转换为Markdown代码块格式。

请确保输出的大纲结构清晰，易于阅读，并且能够直接用于生成PPT。如果输入是纯文本，请你自行判断并划分章节；如果输入是Markdown格式，请你在此基础上进行优化和结构化。

**示例输出格式（Markdown）**：

```markdown
# PPT主标题

## 第一章：章节标题一

### 小节标题一

- 要点一
- 要点二

### 小节标题二

1. 步骤一
2. 步骤二

## 第二章：章节标题二

### 小节标题三

| 列头一 | 列头二 |
|---|---|
| 数据一 | 数据二 |

```
"""
    user_message = f"现在，请你处理以下文本内容：\n\n{text}"

    messages=[
        {
            "role": "system",
            "content": system_prompt
        },
        {
            "role": "user",
            "content": user_message
        }
    ]

    response = client.chat.completions.create(
        model="qwen-max",
        messages=messages,
        seed=random.randint(1, 100000) # Add a random seed
    )
    return response.choices[0].message.content


def generate_ppt_content(text: str):
    client = OpenAI(
        api_key="",
        base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
    )
    
    # 1. 生成唯一文件名（output_时间戳_随机数.md）
    timestamp = int(time.time())
    rand_num = random.randint(1000, 9999)
    output_filename = f"output_{timestamp}_{rand_num}.md"
    # 2. 确保输出目录存在
    output_dir = 'outputfiles'  # 建议用英文目录名
    os.makedirs(output_dir, exist_ok=True)

    # 3. 生成完整文件路径
    output_path = os.path.join(output_dir, output_filename)
    
    # 4. 获取大纲内容
    outline_markdown = capture_outline(text, client)
    # print(f"可写权限: {os.access(output_path, os.W_OK)}")  # 检查写入权限
    # 5. 写入新文件
    try:
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(outline_markdown)
        print(f"✅ 已创建新文件: {output_path}")
    except Exception as e:
        print(f"❌ 文件创建失败: {e}")
    
    return outline_markdown

if __name__ == "__main__":
    text="人工智能生成图像检测关键方法综合分析：GFW、NPR 和 UnivFDI. 引言：人工智能生成图像检测的必要性人工智能生成超现实内容的兴起在过去十年中，生成式人工智能（AI）取得了前所未有的进步，以生成对抗网络（GAN）和扩散模型为代表的模型在合成逼真图像方面取得了显著成功 1。这些生成的图像在很大程度上已达到肉眼难以辨别的程度，对媒体的真实性和信任度构成了严峻挑战 2。高质量合成媒体的泛滥引发了人们对虚假信息传播、版权侵犯以及在各个领域潜在滥用的严重担忧，这凸显了对强大检测机制的迫切需求 1。泛化能力的关键挑战人工智能生成图像检测领域面临的一个核心且持续存在的挑战是，检测器能否有效泛化到由先前未见或持续演进的生成模型创建的图像 1。这通常被称为“分布外”或“跨生成器”泛化。现有检测器在面对“跨场景”内容或新的生成器架构时，其准确性往往会大幅下降，这通常是由于它们过度拟合了训练数据中存在的特定伪造模式或“语义伪影” 9。这种现象揭示了其在捕获真正通用伪造线索方面的根本局限性。所讨论方法的概述本报告将对三种在人工智能生成图像检测和泛化方面具有不同侧重的突出方法进行全面分析：生成对抗网络指纹水印（GFW）、Tan 等人提出的噪声模式去除（NPR）方法 ，以及通用取证检测器（UnivFD）。每种方法都利用不同类型的固有痕迹或学习特征，提供了识别合成内容的独特途径。II. 生成对抗网络指纹水印（GFW）：追踪固有生成器签名“GAN 指纹”的定义“GAN 指纹”是指生成模型在其生成的图像中留下的微小、通常难以察觉的统计模式或独特痕迹 1。这些并非显式嵌入的水印，而是模型架构、训练过程乃至随机初始化所产生的无意副产品 13。Yu 等人 13 的开创性工作确立了这些固有 GAN 指纹的存在性、独特性和持久性。他们的研究表明，即使 GAN 训练参数（如架构、特定训练数据或随机初始化种子）存在微小差异，也会在生成的图像中产生独特且可归因的指纹 13。“指纹识别”的双重目的：检测与知识产权保护在人工智能生成内容的大背景下，“指纹识别”一词可指代两种不同的应用，这对于理解 GFW 至关重要。首先是知识产权（IP）保护，这涉及将唯一标识符（类似于水印）主动嵌入到模型或其输出中，以进行版权验证和所有权认证 6。此类方案通常需要模型开发者的配合，并涉及生成独特的样本-标签对来表征目标模型 15。然而，这些嵌入式水印可能会被有动机的攻击者擦除或伪造 6。其次是取证检测，这是一种被动识别生成过程本身留下的固有统计模式或“痕迹”的方法，无需事先嵌入 1。其目标是将图像分类为真实图像或人工智能生成图像，并可能将其归因于特定来源 13。在用户查询的语境中，GFW 作为与 SFLD 进行对比的方法并提供了性能数据，它主要指的是对这些固有 GAN 指纹的取证检测，用于区分人工智能生成图像。这种方法利用了 GAN 留下稳定、独特痕迹的事实，无需修改生成模型或增加额外的嵌入负担即可进行检测 13。这种区分至关重要，因为它明确了 GFW 作为一种取证工具的操作机制，其有效性依赖于这些固有痕迹的稳定性和可检测性，这在图像经过各种降级处理后可能面临挑战。固有指纹检测的底层机制GFW 类方法通过分析低级图像特征来识别这些微妙的痕迹。常见的方法包括：频域分析： 检测图像频谱中生成模型特有的特定异常或偏差 14。噪声模式： 识别与真实相机捕获图像中发现的噪声模式不同的统计规律或噪声模式 17。架构伪影： 利用生成模型（特别是 GAN）构建图像的特定方式，例如上采样层引入的微小模式 1。这些指纹在不同频率和补丁大小下的持久性，以及它们不被更明显、可感知的伪影所主导的事实，使其在检测中具有重要价值 13。然而，实际挑战在于开发鲁棒的提取和分类技术，以在真实世界场景中可靠地识别这些微妙模式，尤其是在图像经过常见后处理降级（如压缩）之后 13。III. 噪声模式去除（NPR）：利用上采样伪影核心设计原则噪声模式去除（NPR）方法，由 Tan 等人  提出 18，专门设计用于利用生成模型中上采样操作产生的可预测和通用伪影。这些操作在大多数流行的生成器架构中普遍存在，包括 GAN 和扩散模型，因为它们对于将低分辨率潜在表示转换为高分辨率图像至关重要 18。其根本思想是，这些上采样层在像素层面引入了特定的、可检测的模式或微小噪声，可作为区分合成内容和真实图像的可靠线索 18。邻近像素关系（NPR）机制与以往主要在频域中考虑上采样对整个图像影响的研究不同 14，Tan 等人的方法侧重于在局部图像像素层面探索上采样层的痕迹，从而提供了对其影响更细致的理解 18。这种方法论上的转变至关重要。虽然一些 GFW 变体等基于频率的方法 14 分析更广泛的光谱异常，但 NPR 对局部像素相互依赖性的关注（例如，最近邻上采样后 2x2 像素的共享）提供了一种更精细、可能更鲁棒的伪影捕获方式。局部模式通常在不同的生成架构中更具普遍性，并且比全局频率模式更不易受整体图像内容变化的影响。该机制植根于上采样如何影响像素相互依赖性：在上采样操作（例如，最近邻插值）之后，缩放特征图中的局部像素表现出强烈的相关性（例如，2x2 像素块可能共享相同的值）。当这些缩放特征随后由卷积层处理时，这些固有的关系在最终生成的图像中表现为可辨别的模式 18。NPR 通过提取局部图像网格内的差异来捕获这些局部相互依赖性，形成一种本质上是相对和局部的伪影表示，使其对全局图像内容变化具有鲁棒性 18。这种对底层生成操作的局部化效应的深入理解，能够开发出更具鲁棒性和泛化能力的检测方法。对泛化能力的贡献上采样操作在各种生成模型（GAN、扩散模型和其他基于 CNN 的生成器）中的广泛使用，使得 NPR 成为一种高度可泛化的伪影表示 18。通过关注各种架构共有的基本低级操作，NPR 增强了其检测来自未知来源图像的能力。实验结果表明，NPR 具有强大的泛化能力，能够检测来自未知生成模型的图像，例如，一个在 GAN 模型（ProGAN）上训练的检测器成功检测了来自最近生成的扩散模型的图像 18。该方法在深度伪造检测中取得了显著的性能提升，比现有方法提高了 12.8% 19。IV. 通用取证检测器（UnivFD）：迈向广泛泛化“通用”目标通用取证检测器（UnivFD） 的设计理念是实现人工智能生成图像检测的广泛泛化。其目标是构建一个能够针对各种已知生成模型以及更关键的未知生成模型进行稳健可靠检测的检测器 1。这一目标直接解决了许多现有检测器所面临的显著局限性，即它们在面对“来自未见模型的图像时会失效” 2，凸显了对真正通用能力的迫切需求。方法论：利用预训练基础模型UnivFD 的核心方法论是利用一个强大的预训练图像编码器来捕获图像中的高级语义信息 12。具体而言，UnivFD 将中心裁剪的 224x224 图像作为输入提供给 CLIP 编码器 12。CLIP（对比语言-图像预训练）是一个大规模视觉-语言模型，以其在多样化互联网数据上的广泛预训练而闻名，使其能够学习到强大的、任务无关的图像嵌入，从而捕捉丰富的语义理解 1。这种方法体现了“少样本”和基于基础模型的泛化能力的出现。CLIP 等基于 CLIP 的检测器 1 展现出“令人惊讶的泛化能力和跨不同架构的强大鲁棒性”，并且被认为是“少样本”学习器。这意味着，与需要大量、特定于生成器的数据集进行训练不同，这些模型只需少量示例即可适应新的生成模型。这种能力直接源于 CLIP 在多样化真实世界数据上的广泛预训练 24，使其能够学习到强大的高级语义特征，从而有效检测人工智能生成内容所特有的分布差异 23。因此，UnivFD 预示着人工智能生成图像检测的一个重要方向，即朝着更少依赖于对每一种可能的生成模型进行详尽训练的模型发展。这种方法对于在生成式人工智能快速持续演进的背景下保持检测效率至关重要，因为新的模型不断涌现。挑战与局限性尽管 UnivFD 抱有“通用”的愿景，但它已被观察到表现出“对训练图像中观察到的内容的偏见” 12。这表明它可能无意中学习了与训练期间所见内容相关的“另一种特定伪造特性”，而非真正的通用伪造特征。例如，如果 UnivFD 的训练集中缺少某个新类别（如“StyleGAN-卧室”），它可能会错误地将该类别的 GAN 生成图像分类为真实图像 12。这凸显了实现真正通用性所面临的持续挑战，即检测器必须有效地区分伪造模式和图像的语义内容 9。泛化能力基准测试的演进在 UnivFD 的评估背景下，对泛化能力基准测试的理解也在不断演进。SFLD 论文中将 UnivFD  作为对比方法，并在 Table 8 中列出其性能数据。同时，2 将引用  与 Epstein 等人提出的“人工智能生成图像的在线检测”及其 Ai-GenBench 基准测试联系起来。Ai-GenBench 被描述为一个“时间评估框架”，旨在通过按生成模型的历史发布顺序逐步训练检测方法，来测试其对新生成模型的泛化能力 5。这代表了一种比静态基准测试更严格、更真实的“通用”能力测试 2。UnivFD 在此类背景下进行评估，表明其设计明确旨在应对这种具有挑战性的时间泛化问题。这种对泛化能力定义日益复杂化的趋势，从简单的跨架构泛化扩展到跨场景泛化，以及更关键的时间泛化，推动了 Ai-GenBench 等动态基准测试的开发和采用，这对于在真正鲁棒和面向未来的人工智能生成图像检测方面取得进展至关重要。V. 交叉分析：应对泛化挑战泛化策略的综合在人工智能生成图像检测领域，研究人员正在探索多种策略来应对泛化挑战，每种策略都利用不同类型的图像特征：GFW 类方法（取证指纹识别）利用生成过程固有的、低级的统计模式 13。它们的优势在于识别这些微妙的痕迹，这些痕迹较少依赖于高级图像内容，从而在不同 GAN 之间提供了一种架构泛化形式。NPR 通过细致分析局部像素关系来专门针对普遍存在的上采样伪影 18。这种方法的泛化能力源于上采样操作在各种生成模型（GAN 和扩散模型）中的普遍性，使其对特定生成器架构的变化具有鲁棒性 18。UnivFD 采用强大的预训练基础模型（如 CLIP）来捕获高级语义特征和分布差异 12。这种方法旨在通过深入理解自然图像统计数据来实现广泛泛化，从而实现对新模型的“少样本”适应 1。混合方法（例如 SFLD、AIDE）代表了一种新兴且极具前景的趋势，它们结合了这些不同的策略。例如，SFLD（与 GFW、NPR 和 UnivFD 进行比较）和 AIDE 27 通过将低级纹理信息（例如通过 PatchShuffle 12）与高级语义特征（例如来自 CLIP 12）相结合，展示了一种协同方法。这旨在实现鲁棒性（抵御图像降级）与对不同内容和生成器的广泛泛化之间的平衡。这种多层次特征融合的趋势表明，仅仅依靠单一类型的特征（例如，仅低级指纹或仅高级语义）不足以实现鲁棒、通用的检测。低级特征对微妙的伪造敏感，但可能对常见的图像处理脆弱。来自基础模型的高级特征提供广泛的内容泛化，但可能错过微妙的、特定的伪影。将它们结合起来可以利用它们的互补优势。常见陷阱与不断演进的理解过度拟合“语义伪影”或“内容偏差”： 许多检测器反复出现的一个局限性是它们倾向于过度拟合训练集中存在的内容或特定伪造模式 9。这种“语义伪影”问题导致检测器在遇到训练中未见过的新场景或内容类别时泛化能力差。这凸显了将伪造线索与语义信息有效分离的关键需求。训练数据多样性有限： 检测器的有效性与其训练数据的规模和多样性直接相关，特别是所包含的生成模型的数量和种类 2。静态、有限的数据集本质上阻碍了真正通用检测器的开发，因为它们无法捕获合成图像生成领域广阔且不断演进的格局。基础模型的作用大型预训练模型，如 CLIP 和其他视觉基础模型（VFM），正日益被认为是提高泛化能力的关键 1。它们捕获真实世界数据丰富、可泛化表示的能力有助于减轻对特定伪造模式的过度拟合，并显著增强对未见生成器的检测能力。它们提供了一个强大的特征空间，可以适应取证任务。此外，该领域正在出现一个深刻的概念转变：从检测“伪造性”转向检测“真实性”。大多数检测方法（GFW、NPR、UnivFD）都侧重于识别“生成伪影”或“指纹”（即检测“伪造性”）。然而，29 提出了一种截然不同的理念：“专注于提取真实摄影图像的低级内在特征”，认为识别来自生成伪影的人工智能生成图像是不可持续的，因为模型不断演进。这是一种深刻的哲学转变。如果“真实性”拥有比“伪造性”（一个不断变化的目标）更稳定、不可变的特征，那么学习识别真实图像的这些内在属性可能会提供一种更稳定、真正通用的检测机制。这种哲学辩论可能会显著影响未来的研究方向。专注于表征和检测“真实性”可能会带来更具弹性和面向未来的检测系统，而不是永无止境地追逐和识别不断演进的“伪造性”。这与 30 中提到的一类异常检测方法的发展也相呼应，其中模型仅从真实数据中学习。表1：人工智能生成图像检测关键方法比较分析方法名称核心思想/机制利用的伪影/特征类型对泛化能力的主要贡献观察到的优势观察到的局限性/挑战关键相关来源GFW (取证指纹识别)检测 GAN 训练过程固有的统计模式固有 GAN 指纹架构无关的检测具有坚实理论基础，无需修改生成模型对后处理的鲁棒性，需要大量训练数据1NPR利用上采样操作产生的局部像素相互依赖性上采样伪影，局部像素关系对各种生成器（GANs, DM）的鲁棒性性能显著提升，跨生成器泛化能力强专注于低级伪影，可能对某些内容不敏感18UnivFD利用预训练图像编码器（如 CLIP）捕获高级语义信息高级语义特征，分布差异对新模型的少样本适应，广泛适用性利用大型预训练模型，减少数据依赖存在内容偏差，对未见内容可能误判1表2：人工智能生成图像检测泛化能力基准测试的演进基准名称关键特征大致规模（模型/图像）涵盖的生成模型对泛化研究的影响关键相关来源Ai-GenBench [32/Epstein et al.]时间评估框架，专注于未见模型14 个模型 / 57 万张图像扩散模型解决了静态数据集的局限性，推动时间泛化研究2Community Forensics [Park et al.]大规模多样性生成器，跨场景泛化4803 个模型 / 270 万张图像扩散模型，GAN，自回归，基于 CNN实现了对多样化架构的评估，推动了真实世界场景下的泛化2VI. 结论与未来展望贡献与局限性总结人工智能生成图像检测领域正处于快速发展之中，旨在应对日益逼真的合成媒体所带来的挑战。GFW 类方法通过利用生成模型固有的稳定指纹，为取证检测提供了基础性方法。虽然它们提供了架构泛化能力，但其对后处理的实际鲁棒性以及对大量训练数据的需求仍需考虑。NPR 通过细致分析局部像素层面的通用上采样伪影，提供了一种高度可泛化的解决方案。它专注于各种生成模型中普遍存在的低级操作，已显示出显著的性能提升和跨生成器泛化能力。UnivFD 率先使用强大的预训练基础模型（如 CLIP）通过高级语义理解实现广泛泛化。然而，它面临内容偏差的挑战，表明真正的通用性需要超越高级特征。混合方法（如 SFLD）的出现，结合了低级伪影检测和高级语义理解，代表了一个有前景的方向，旨在利用不同特征类型的互补优势来增强鲁棒性和泛化能力。关键需求的重申生成式人工智能的演进速度之快，要求检测方法不断创新。生成与检测之间的“军备竞赛”仍在持续，对未见和不断演进模型的鲁棒泛化仍然是保障数字真实性的首要挑战。未来研究方向未来的研究应集中于以下几个关键领域，以推动人工智能生成图像检测的边界：高级混合模型： 进一步开发多模态和多尺度混合架构，智能地整合低级伪影检测和来自基础模型的高级语义理解，以实现灵敏度和鲁棒性之间的最佳平衡。解耦表示： 继续研究能够明确解耦伪造线索与语义内容的方法，对于克服内容偏差和提高检测器在不同场景类型中的泛化能力至关重要。动态与大规模基准测试： 持续开发和广泛采用时间性和大规模多样化的基准测试（如 Ai-GenBench 和 Community Forensics），对于实现对未来生成模型的真正泛化进行现实评估和推动进展不可或缺。“真实性”检测范式： 探索将重点从检测“伪造性”（这是一个不断变化的目标）转向表征和检测“真实摄影图像的内在属性”的哲学和实践意义，作为一种更稳定和面向未来的方法。可解释性与可解释性： 随着人工智能生成内容检测系统变得越来越复杂并应用于敏感领域（例如，取证、法律环境），确保其可解释性 30 和提供清晰决策解释的能力对于建立信任和促进其实际应用至关重要。"
    r = generate_ppt_content(text)
    print(r)
